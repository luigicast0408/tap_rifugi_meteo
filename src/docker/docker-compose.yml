services:
  # --- INGESTION SERVICES ---
  huts-fech:
    build:
      context: ../../
      dockerfile: src/docker/Dockerfile
    container_name: huts-fech
    volumes:
      - ../../:/app
      - ../../data:/data
    working_dir: /app
    command: python -u src/ingestion/fetch_huts.py
    networks:
      - tap

  weather-fech:
    build:
      context: ../../
      dockerfile: src/docker/Dockerfile
    container_name: weather-fech
    depends_on:
      - huts-fech
    volumes:
      - ../../:/app
      - ../../data:/data
    working_dir: /app
    command: python -u src/ingestion/fetch_weather.py
    networks:
      - tap

  # --- LOG SHIPPER ---
  fluent-bit:
    image: fluent/fluent-bit:latest
    container_name: fluent-bit
    volumes:
      - ../fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf
      - ../fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf
      - ../../data:/data
    depends_on:
      - weather-fech
      - kafka
    networks:
      - tap

  # --- KAFKA CLUSTER ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - tap

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - tap

  # --- MONITORING (UI) ---
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - tap

  # --- INITIALIZATION ---
  kafka-topics-init:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - kafka
    networks:
      - tap
    command: >
      bash -c "sleep 15 &&
      kafka-topics --create --if-not-exists --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --topic rifugi &&
      kafka-topics --create --if-not-exists --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --topic meteo"

  spark-master:
    image: apache/spark:3.4.1
    container_name: spark-master
    user: root
    ports:
      - "8081:8080" # Spark Web UI
      - "7077:7077" # Spark Master Port
    networks:
      - tap
    volumes:
      - ../:/opt/spark/work-dir/src
      - ../../models:/opt/spark/work-dir/models
      - ../../data:/opt/spark/work-dir/data
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

  spark-processor:
    image: apache/spark:3.4.1
    container_name: spark-processor
    user: root
    depends_on:
      - kafka
      - elasticsearch
    networks:
      - tap
    volumes:
      - ../processing:/opt/spark/work-dir/processing
      - ../../models:/opt/spark/work-dir/models
      - ../../data:/opt/spark/work-dir/data
    command: >
      bash -c "pip install numpy && 
      /opt/spark/bin/spark-submit 
      --master local[*] 
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,org.elasticsearch:elasticsearch-spark-30_2.12:8.11.3 
      /opt/spark/work-dir/processing/processor.py"

  spark-trainer:
    image: apache/spark:3.4.1
    container_name: spark-trainer
    user: root
    networks:
      - tap
    volumes:
      - ../:/opt/spark/work-dir/src
      - ../../models:/opt/spark/work-dir/models
      - ../../data:/opt/spark/work-dir/data
    profiles:
      - training
    command: >
      bash -c "pip install numpy && 
      /opt/spark/bin/spark-submit 
      --master local[*]
      /opt/spark/work-dir/models/train_model.py"

  elasticsearch:
    image: elasticsearch:8.11.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    networks:
      - tap
    volumes:
      - ./elasticsearch_data:/usr/share/elasticsearch/data

  kibana:
      image: kibana:8.11.3
      container_name: kibana
      depends_on:
        - elasticsearch
      ports:
        - "5605:5601"
      environment:
        - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
        - XPACK_SECURITY_ENABLED=false
        # Aggiungi queste per evitare l'errore del Registry se non usi Elastic Agent
        - xpack.fleet.enabled=false
      networks:
        - tap

networks:
  tap:
    driver: bridge